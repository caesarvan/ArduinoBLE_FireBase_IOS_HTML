{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution1D, MaxPooling1D, Flatten\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.callbacks import TensorBoard\n",
    "# from keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio \n",
    "from sklearn.preprocessing import normalize\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (3200, 1000)\n",
      "x_test  (3200, 250)\n",
      "y_train (1, 1000)\n",
      "y_test  (1, 250)\n",
      "x_train (1000, 200, 16)\n",
      "x_test  (250, 200, 16)\n",
      "y_train (1, 1000)\n",
      "y_test  (1, 250)\n",
      "************ label to on-hot ***************\n",
      "y_train [[0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "y_test  [[0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "matfn = 'posture_5_data.mat'\n",
    "\n",
    "data = sio.loadmat(matfn)  \n",
    "x_train = data['x_train'].T\n",
    "x_test = data['x_test'].T\n",
    "y_train = data['y_train'].T\n",
    "y_test = data['y_test'].T\n",
    "\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"x_test \", x_test.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"y_test \", y_test.shape)\n",
    "\n",
    "#将数据集数据进行归一化，归一方法采用StandardScaler()\n",
    "# # dataset Standardscalization\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# x_train = scaler.fit_transform(\n",
    "#     x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 200, 16)\n",
    "\n",
    "# x_test = scaler.transform(\n",
    "#     x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 200, 16)\n",
    "\n",
    "x_train = x_train.astype(np.float32).reshape(-1, 200, 16)\n",
    "x_test = x_test.astype(np.float32).reshape(-1, 200, 16)\n",
    "\n",
    "\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"x_test \", x_test.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"y_test \", y_test.shape)\n",
    "\n",
    "print('************ label to on-hot ***************')\n",
    "y_train= np.transpose(y_train)\n",
    "y_test = np.transpose(y_test)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=5)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=5)\n",
    "\n",
    "print(\"y_train\", y_train)\n",
    "print(\"y_test \", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 00:21:14.967705: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/fangaoyige/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 此部分为CNN神经网络内部结构\n",
    "model = Sequential()\n",
    "#创建序列模型\n",
    "model.add(Dense(128,kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "#将训练数据输入进行初始化\n",
    "# Conv layer 1 output shape (1,50,32)16,200,32\n",
    "# 添加卷积层1 各个参数什么意思百度 \n",
    "#注释后面参数不对，不用管，懒得改，后面类似\n",
    "model.add(Convolution1D(filters=16,kernel_size=3,strides=1, padding='same',))   # Padding method\n",
    "model.add(Activation('relu'))\n",
    "#Relu激活函数\n",
    "# Pooling layer 1 (max pooling) output shape (1, 25, 32)\n",
    "model.add(MaxPooling1D(pool_size=3,strides=3,padding='same',))    # Padding method\n",
    "#添加池化层1，各个参数什么意思百度\n",
    "# =====================================================\n",
    "# Conv layer 2 output shape (1,25,64)\n",
    "model.add(Convolution1D(32, 3, strides=1, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling layer 2 (max pooling) output shape (1, 25, 32)\n",
    "model.add(MaxPooling1D(2, 2, 'same'))\n",
    "model.add(Activation('relu'))\n",
    "# =====================================================\n",
    "# Conv layer 3 output shape (1，50，128)\n",
    "model.add(Convolution1D(64, 3, strides=1, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling layer 3 (max pooling) output shape (1, 25, 32)\n",
    "model.add(MaxPooling1D(2, 2, 'same'))\n",
    "\n",
    "# =====================================================\n",
    "# Conv layer 4 output shape (1，50，128)\n",
    "model.add(Convolution1D(128, 3, strides=1, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling layer 4 (max pooling) output shape (1, 25, 32)\n",
    "model.add(MaxPooling1D(2, 2, 'same'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "# 添加dropout层，训练时丢掉一部分数据，防止训练过拟合，失去泛化能力\n",
    "\n",
    "# Fully connected layer 1 input shape (1*25*128) \n",
    "model.add(Flatten())\n",
    "# 将网络铺平,以连通到后面的全连接层\n",
    "\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "#添加512通道的全连接层1 激活函数为Relu\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "# 添加dropout层，训练时丢掉一部分数据，防止训练过拟合，失去泛化能力\n",
    "\n",
    "# Fully connected layer 2 to shape (20) for 10 classes\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "# 添加20通道的全连接层，用于将结果分类为20中不同的姿势\n",
    "# 采用Softmax激活函数\n",
    "\n",
    "# Another way to define your optimizer\n",
    "adam = Adam(lr=1e-2)\n",
    "#训练优化器采用Adam，学习速率是0.0001\n",
    "\n",
    "# We add metrics to get more results you want to see\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#损失函数定义为交叉熵，衡量标准定义为准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 6s 435ms/step - loss: 317.8624 - accuracy: 0.2080 - val_loss: 3.1868 - val_accuracy: 0.1840\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 2s 294ms/step - loss: 1.6172 - accuracy: 0.1850 - val_loss: 3.4006 - val_accuracy: 0.2160\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 1.6092 - accuracy: 0.2050 - val_loss: 4.1042 - val_accuracy: 0.1800\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 1.6112 - accuracy: 0.2050 - val_loss: 1.6141 - val_accuracy: 0.1680\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 1.6096 - accuracy: 0.2180 - val_loss: 1.6152 - val_accuracy: 0.1680\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 1.6110 - accuracy: 0.1890 - val_loss: 1.6131 - val_accuracy: 0.1760\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 2s 235ms/step - loss: 1.6110 - accuracy: 0.1880 - val_loss: 1.6123 - val_accuracy: 0.1760\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 1.6110 - accuracy: 0.1880 - val_loss: 1.6142 - val_accuracy: 0.1760\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 1.6095 - accuracy: 0.1930 - val_loss: 1.6127 - val_accuracy: 0.1680\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 1.6106 - accuracy: 0.2040 - val_loss: 1.6139 - val_accuracy: 0.1760\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 1.6120 - accuracy: 0.1990 - val_loss: 1.6155 - val_accuracy: 0.1680\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 1s 193ms/step - loss: 1.6098 - accuracy: 0.2090 - val_loss: 1.6132 - val_accuracy: 0.1680\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 1.6107 - accuracy: 0.1990 - val_loss: 1.6127 - val_accuracy: 0.1760\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 1s 189ms/step - loss: 1.6113 - accuracy: 0.1960 - val_loss: 1.6122 - val_accuracy: 0.1760\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 1.6097 - accuracy: 0.2000 - val_loss: 1.6122 - val_accuracy: 0.1680\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 1.6104 - accuracy: 0.2110 - val_loss: 1.6130 - val_accuracy: 0.1760\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 1.6107 - accuracy: 0.1950 - val_loss: 1.6135 - val_accuracy: 0.1760\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 1.6097 - accuracy: 0.2020 - val_loss: 1.6139 - val_accuracy: 0.1760\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 1.6079 - accuracy: 0.2110 - val_loss: 1.6131 - val_accuracy: 0.1680\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 1.6082 - accuracy: 0.2070 - val_loss: 1.6136 - val_accuracy: 0.1680\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 1.6100 - accuracy: 0.1920 - val_loss: 1.6135 - val_accuracy: 0.1680\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 1.6107 - accuracy: 0.2200 - val_loss: 1.6140 - val_accuracy: 0.1680\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 1.6085 - accuracy: 0.1960 - val_loss: 1.6132 - val_accuracy: 0.1680\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 1s 187ms/step - loss: 1.6089 - accuracy: 0.2190 - val_loss: 1.6117 - val_accuracy: 0.1680\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 1.6104 - accuracy: 0.1900 - val_loss: 1.6122 - val_accuracy: 0.1760\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 1.6083 - accuracy: 0.2140 - val_loss: 1.6126 - val_accuracy: 0.1760\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 2s 254ms/step - loss: 1.6100 - accuracy: 0.1940 - val_loss: 1.6134 - val_accuracy: 0.1760\n",
      "Epoch 28/200\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 1.6107 - accuracy: 0.2070"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j7/3ltnn39s22z0jb6b2gzjrlv80000gn/T/ipykernel_45679/3093076639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#调用Tensorboard进行实时监控，不会用建议注释掉这一行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Training ------------')\n",
    "\n",
    "# Tensorboard = TensorBoard(log_dir=\"./history\") # Monitor in real time\n",
    "#调用Tensorboard进行实时监控，不会用建议注释掉这一行\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=200, batch_size=128 , validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "print('\\nTesting ------------')\n",
    "# Evaluate the model with the metrics we defined earlier\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = np.argmax(model.predict(x_test),axis=1)\n",
    "print(y_pre)\n",
    "\n",
    "# 绘制训练 & 验证的准确率值\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 绘制训练 & 验证的损失值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matfn = 'posture_5_data.mat'\n",
    "data = sio.loadmat(matfn)  \n",
    "y_test = data['y_test']\n",
    "\n",
    "y_test.resize(250,)\n",
    "print(type(y_test))\n",
    "print(np.array(y_test).shape)\n",
    "print(y_test)\n",
    "\n",
    "print(np.array(y_pre).shape)\n",
    "print(type(y_pre))\n",
    "print(y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "con_mat = confusion_matrix(y_test, y_pre)\n",
    "\n",
    "con_mat_norm = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]     # 归一化\n",
    "con_mat_norm = np.around(con_mat_norm, decimals=2)\n",
    "\n",
    "# === plot ===\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(con_mat_norm, annot=True, cmap='Blues')\n",
    "\n",
    "plt.ylim(0, 5)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
